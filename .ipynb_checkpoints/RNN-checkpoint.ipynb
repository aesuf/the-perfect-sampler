{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3347b2",
   "metadata": {},
   "source": [
    "# RNN Training #\n",
    "## Jackson Cornell ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e38388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5cb0e7",
   "metadata": {},
   "source": [
    "## From feature_engineering.ipynb, delete later ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-io\n",
    "import librosa\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import IPython\n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, Input\n",
    "import tensorflow_io as tfio\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "!git clone https://github.com/aesuf/orchestral_samples;\n",
    "    \n",
    "def trim_sample(y,sr,seconds):\n",
    "  return librosa.util.fix_length(y,size=int((sr*seconds)))\n",
    "\n",
    "def get_filenames():\n",
    "  files = os.listdir('orchestral_samples/data')\n",
    "  return list(\n",
    "      map(\n",
    "      lambda file: 'orchestral_samples/data/' + file , files)\n",
    "  )\n",
    "\n",
    "def scale_minmax(X, min=0.0, max=1.0):\n",
    "    X_std = (X - X.min()) / (X.max() - X.min())\n",
    "    X_scaled = X_std * (max - min) + min\n",
    "    return X_scaled\n",
    "\n",
    "def get_instruments():\n",
    "  instruments = {\n",
    "  \"bass-clarinet\": 0,\n",
    "  \"contrabassoon\": 1,\n",
    "  \"cello\": 2,\n",
    "  \"clarinet\": 3,\n",
    "  \"bassoon\": 4,\n",
    "  \"double-bass\": 5,\n",
    "  \"french-horn\": 6,\n",
    "  \"guitar\": 7,\n",
    "  \"mandolin\": 8,\n",
    "  \"oboe\": 9,\n",
    "  \"saxophone\": 10,\n",
    "  \"trombone\": 11,\n",
    "  \"trumpet\": 12,\n",
    "  \"tuba\": 13,\n",
    "  \"viola\": 14,\n",
    "  \"violin\": 15,\n",
    "}\n",
    "  return instruments\n",
    "\n",
    "def get_y_value(file):\n",
    "  instruments = get_instruments()\n",
    "  for instrument in instruments:\n",
    "    if file.find(instrument)!=-1:\n",
    "      return instruments[instrument]\n",
    "  return \"NULL\"\n",
    "\n",
    "def get_y_values():\n",
    "  files = os.listdir('orchestral_samples/data')\n",
    "  return np.array(\n",
    "      list(\n",
    "          map(get_y_value,files)\n",
    "          )\n",
    "      )\n",
    "  \n",
    "def get_labels():\n",
    "  inv_map = {v: k for k, v in get_instruments().items()}\n",
    "  return np.array(list(inv_map.items()))[:,[1]]\n",
    "\n",
    "files = get_filenames()\n",
    "\n",
    "i = np.random.randint(0,len(files)-1)\n",
    "librosa.display.waveshow(*librosa.load(files[i]))\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "def spectrogram(y):\n",
    "  nfft=512\n",
    "  window=512\n",
    "  stride=256\n",
    "  s = tfio.audio.spectrogram(y, nfft=nfft, window=window, stride=stride)\n",
    "  s = tfio.audio.melscale(s, rate=22050, mels=128, fmin=0, fmax=11025)\n",
    "  return tfio.audio.dbscale(s,top_db=80)   \n",
    "def load_wav_22k_mono(filename):\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_samples=66000,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=22050)\n",
    "    return wav\n",
    "def process_feature(file_name):\n",
    "  return spectrogram(load_wav_22k_mono(file_name))\n",
    "dataset = (tf.data.Dataset.from_tensor_slices(get_filenames())\n",
    "          .map(process_feature, num_parallel_calls=AUTOTUNE))\n",
    "x = np.array([d.numpy() for d in dataset])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x, get_y_values(), test_size=0.33, random_state=42)\n",
    "\n",
    "labels=get_labels()\n",
    "\n",
    "y_train_cat = keras.utils.to_categorical(y_train)\n",
    "y_test_cat = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f740f3",
   "metadata": {},
   "source": [
    "### Load data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c39b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# load data\n",
    "\n",
    "# split into training, validation, and test set\n",
    "x_train, x_test, t_train, t_test = train_test_split(images, labels, test_size=0.20)\n",
    "x_train, x_val, t_train, t_val = train_test_split(x_train, t_train, test_size=0.20)\n",
    "\n",
    "# print sizes\n",
    "print(\"Training data size:\", x_train.shape)\n",
    "print(\"Validation data size:\", x_val.shape)\n",
    "print(\"Testing data size:\", x_test.shape)\n",
    "\n",
    "# display data example\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9362b85",
   "metadata": {},
   "source": [
    "### Train model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model shape\n",
    "input_shape=(128,1000)\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(128,input_shape=input_shape))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "#model.add(Dense(48, activation='relu'))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Dense(24, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam',loss='SparseCategoricalCrossentropy',metrics=['acc'])\n",
    "\n",
    "# train model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=72, validation_data=(X_test, y_test), shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f945956",
   "metadata": {},
   "source": [
    "### Validate model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45223b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "history_dict=history.history\n",
    "loss_values=history_dict['loss']\n",
    "acc_values=history_dict['acc']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "val_acc_values=history_dict['val_acc']\n",
    "epochs=range(1,51)\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,5))\n",
    "ax1.plot(epochs,loss_values,'co',label='Training Loss')\n",
    "ax1.plot(epochs,val_loss_values,'m', label='Validation Loss')\n",
    "ax1.set_title('Training and validation loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax2.plot(epochs,acc_values,'co', label='Training accuracy')\n",
    "ax2.plot(epochs,val_acc_values,'m',label='Validation accuracy')\n",
    "ax2.set_title('Training and validation accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "plt.show()\n",
    "\n",
    "# display confusion matrix\n",
    "TrainLoss, Trainacc = model.evaluate(X_train, y_train)\n",
    "TestLoss, Testacc = model.evaluate(X_test, y_test)\n",
    "t_pred = model.predict(X_test)\n",
    "print('Confusion_matrix: ',tf.math.confusion_matrix(y_test, np.argmax(t_pred,axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9dad4",
   "metadata": {},
   "source": [
    "### Save model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb279a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment when we start getting good results\n",
    "#model.save('RNN_classifier')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
